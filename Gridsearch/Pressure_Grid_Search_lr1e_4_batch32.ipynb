{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Pressure_Grid_Search_lr1e-4_batch32.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOGMyxuwjIt8sCXKSh0ry7L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acse-srm3018/DeeplearningProxy/blob/main/Gridsearch/Pressure_Grid_Search_lr1e_4_batch32.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9PQE47vGAl_",
        "outputId": "243b4715-4e04-482f-e16e-01fe9cd406c2"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 25 18:46:35 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi27NRCrGRba",
        "outputId": "ee6232d4-7cb2-4d40-f69a-90f56b30cb0a"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "9D0wgpehaCVX",
        "outputId": "1f637b37-7b52-4d3a-dd8d-efdce37440e2"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-54d62708-18c5-4011-9464-6bf3f437ea2b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-54d62708-18c5-4011-9464-6bf3f437ea2b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving layers.py to layers (4).py\n",
            "Saving unet_uae.py to unet_uae (4).py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers.py': b'\"\"\"Import required libraries and modules.\"\"\"\\r\\n\\r\\nimport tensorflow as tf\\r\\nfrom keras import backend as K\\r\\nfrom keras.engine.topology import Layer\\r\\nfrom keras.layers.merge import add\\r\\n# from keras.engine import InputSpec\\r\\nfrom keras.layers import InputSpec\\r\\nfrom keras.layers.core import Activation\\r\\nfrom keras.layers.convolutional import Conv2D, UpSampling2D\\r\\nfrom keras.layers import BatchNormalization, ConvLSTM2D\\r\\nfrom keras.layers import TimeDistributed, Reshape, RepeatVector\\r\\nfrom keras import regularizers\\r\\n\\r\\n\\r\\nreg_weights = 0.00001\\r\\n\\r\\n\\r\\ndef conv_bn_relu(filter_num, row_num, col_num, stride):\\r\\n    \"\"\"\\r\\n    Create Convolutional Batch Norm layer.\\r\\n\\r\\n    Parameters:\\r\\n    ---------\\r\\n    filter_num : int\\r\\n    number of filters to use in convolution layer.\\r\\n    row_num : int\\r\\n    number of row\\r\\n    col_num : int\\r\\n    number of column\\r\\n    stride : int\\r\\n    size of stride\\r\\n    Returns:\\r\\n    ---------\\r\\n    conv_func\\r\\n    \"\"\"\\r\\n    def conv_func(x):\\r\\n        x = Conv2D(filter_num, (row_num, col_num),\\r\\n                   strides=stride,\\r\\n                   padding=\\'same\\',\\r\\n                   kernel_regularizer=regularizers.l2(reg_weights))(x)\\r\\n        x = BatchNormalization()(x)\\r\\n        x = Activation(\"relu\")(x)\\r\\n        return x\\r\\n\\r\\n    return conv_func\\r\\n\\r\\n\\r\\ndef time_conv_bn_relu(filter_num, row_num, col_num, stride):\\r\\n    \"\"\"\\r\\n    Create Convolutional Batch Norm layer.\\r\\n\\r\\n    Parameters:\\r\\n    ---------\\r\\n    filter_num : int\\r\\n    number of filters to use in convolution layer.\\r\\n    row_num : int\\r\\n    number of row\\r\\n    col_num : int\\r\\n    number of column\\r\\n    stride : int\\r\\n    size of stride\\r\\n    Returns:\\r\\n    ---------\\r\\n    conv_func\\r\\n    \"\"\"\\r\\n    def conv_func(x):\\r\\n        x = TimeDistributed(Conv2D(filter_num, (row_num, col_num),\\r\\n                            strides=stride,\\r\\n                            padding=\\'same\\',\\r\\n                            kernel_regularizer=regularizers.\\r\\n                            l2(reg_weights)))(x)\\r\\n        x = TimeDistributed(BatchNormalization())(x)\\r\\n        x = TimeDistributed(Activation(\"relu\"))(x)\\r\\n        return x\\r\\n\\r\\n    return conv_func\\r\\n\\r\\n\\r\\ndef res_conv(filter_num, row_num, col_num, stride=(1, 1)):\\r\\n    \"\"\"\\r\\n    Create Convolutional Batch Norm layer.\\r\\n\\r\\n    Parameters:\\r\\n    ---------\\r\\n    filter_num : int\\r\\n    number of filters to use in convolution layer.\\r\\n    row_num : int\\r\\n    number of row\\r\\n    col_num : int\\r\\n    number of column\\r\\n    stride : int\\r\\n    size of stride\\r\\n    *default = (1,1)\\r\\n    Returns:\\r\\n    ---------\\r\\n    conv_func\\r\\n    \"\"\"\\r\\n    def _res_func(x):\\r\\n        identity = x\\r\\n\\r\\n        a = Conv2D(filter_num, (row_num, col_num),\\r\\n                   strides=stride, padding=\\'same\\',\\r\\n                   kernel_regularizer=regularizers.l2(reg_weights))(x)\\r\\n        a = BatchNormalization()(a)\\r\\n        a = Activation(\"relu\")(a)\\r\\n        a = Conv2D(filter_num, (row_num, col_num),\\r\\n                   strides=stride, padding=\\'same\\',\\r\\n                   kernel_regularizer=regularizers.l2(reg_weights))(a)\\r\\n        y = BatchNormalization()(a)\\r\\n\\r\\n        return add([identity, y])\\r\\n\\r\\n    return _res_func\\r\\n\\r\\n\\r\\ndef time_res_conv(filter_num, row_num, col_num, stride=(1, 1)):\\r\\n    \"\"\"\\r\\n    Create Convolutional Batch Norm layer.\\r\\n\\r\\n    Parameters:\\r\\n    ---------\\r\\n    filter_num : int\\r\\n    number of filters to use in convolution layer.\\r\\n    row_num : int\\r\\n    number of row\\r\\n    col_num : int\\r\\n    number of column\\r\\n    stride : int\\r\\n    size of stride\\r\\n    Returns:\\r\\n    ---------\\r\\n    conv_func\\r\\n    \"\"\"\\r\\n    def _res_func(x):\\r\\n        identity = x\\r\\n\\r\\n        a = TimeDistributed(Conv2D(filter_num, (row_num, col_num),\\r\\n                                   strides=stride, padding=\\'same\\',\\r\\n                                   kernel_regularizer=regularizers.\\r\\n                                   l2(reg_weights)))(x)\\r\\n        a = TimeDistributed(BatchNormalization())(a)\\r\\n        a = TimeDistributed(Activation(\"relu\"))(a)\\r\\n        a = TimeDistributed(Conv2D(filter_num, (row_num, col_num),\\r\\n                                   strides=stride, padding=\\'same\\',\\r\\n                                   kernel_regularizer=regularizers.\\r\\n                                   l2(reg_weights)))(x)\\r\\n        y = TimeDistributed(BatchNormalization())(a)\\r\\n\\r\\n        return add([identity, y])\\r\\n\\r\\n    return _res_func\\r\\n\\r\\n\\r\\ndef dconv_bn_nolinear(nb_filter, nb_row, nb_col, stride=(2, 2),\\r\\n                      activation=\"relu\"):\\r\\n    \"\"\"\\r\\n    Create convolutional Batch Norm layer in decoders.\\r\\n\\r\\n    Parameters:\\r\\n    ---------\\r\\n    filter_num : int\\r\\n    number of filters to use in convolution layer.\\r\\n    row_num : int\\r\\n    number of row\\r\\n    col_num : int\\r\\n    number of column\\r\\n    stride : int\\r\\n    size of stride\\r\\n    Returns:\\r\\n    ---------\\r\\n    dconv_bn\\r\\n    \"\"\"\\r\\n    def _dconv_bn(x):\\r\\n        x = UnPooling2D(size=stride)(x)\\r\\n        x = ReflectionPadding2D(padding=(int(nb_row/2), int(nb_col/2)))(x)\\r\\n        x = Conv2D(nb_filter, (nb_row, nb_col), padding=\\'valid\\',\\r\\n                   kernel_regularizer=regularizers.l2(reg_weights))(x)\\r\\n        x = BatchNormalization()(x)\\r\\n        x = Activation(activation)(x)\\r\\n        return x\\r\\n\\r\\n    return _dconv_bn\\r\\n\\r\\n\\r\\ndef time_dconv_bn_nolinear(nb_filter, nb_row, nb_col,\\r\\n                           stride=(2, 2), activation=\"relu\"):\\r\\n    \"\"\"\\r\\n    Create time convolutional Batch Norm layer in decoders.\\r\\n\\r\\n    Parameters:\\r\\n    ---------\\r\\n    filter_num : int\\r\\n    number of filters to use in convolution layer.\\r\\n    row_num : int\\r\\n    number of row\\r\\n    col_num : int\\r\\n    number of column\\r\\n    stride : int\\r\\n    size of stride\\r\\n    Returns:\\r\\n    ---------\\r\\n    dconv_bn\\r\\n    \"\"\"\\r\\n    def _dconv_bn(x):\\r\\n        x = TimeDistributed(UnPooling2D(size=stride))(x)\\r\\n        x = TimeDistributed(ReflectionPadding2D(padding=(int(nb_row/2),\\r\\n                            int(nb_col/2))))(x)\\r\\n        x = TimeDistributed(Conv2D(nb_filter, (nb_row, nb_col),\\r\\n                                   padding=\\'valid\\',\\r\\n                                   kernel_regularizer=regularizers.\\r\\n                                   l2(reg_weights)))(x)\\r\\n        x = TimeDistributed(BatchNormalization())(x)\\r\\n        x = TimeDistributed(Activation(activation))(x)\\r\\n        return x\\r\\n\\r\\n    return _dconv_bn\\r\\n\\r\\n\\r\\nclass ReflectionPadding2D(Layer):\\r\\n    \"\"\"class for reflectionPadding2D.\"\"\"\\r\\n\\r\\n    def __init__(self, padding=(1, 1), data_format=\"channels_last\", **kwargs):\\r\\n        \"\"\"\\r\\n        Construct class parameters.\\r\\n\\r\\n        parameters:\\r\\n        -------\\r\\n        padding\\r\\n        dim_ordering\\r\\n        \"\"\"\\r\\n        super(ReflectionPadding2D, self).__init__(**kwargs)\\r\\n\\r\\n        if data_format == \\'channels_last\\':\\r\\n            dim_ordering = K.image_data_format()\\r\\n\\r\\n        self.padding = padding\\r\\n        if isinstance(padding, dict):\\r\\n            if set(padding.keys()) <= {\\'top_pad\\', \\'bottom_pad\\',\\r\\n                                       \\'left_pad\\', \\'right_pad\\'}:\\r\\n                self.top_pad = padding.get(\\'top_pad\\', 0)\\r\\n                self.bottom_pad = padding.get(\\'bottom_pad\\', 0)\\r\\n                self.left_pad = padding.get(\\'left_pad\\', 0)\\r\\n                self.right_pad = padding.get(\\'right_pad\\', 0)\\r\\n            else:\\r\\n                raise ValueError(\\'Unexpected key\\'\\r\\n                                 \\'found in `padding` dictionary.\\'\\r\\n                                 \\'Keys have to be in {\"top_pad\", \"bottom_pad\",\\'\\r\\n                                 \\'\"left_pad\", \"right_pad\"}.\\'\\r\\n                                 \\'Found: \\' + str(padding.keys()))\\r\\n        else:\\r\\n            padding = tuple(padding)\\r\\n            if len(padding) == 2:\\r\\n                self.top_pad = padding[0]\\r\\n                self.bottom_pad = padding[0]\\r\\n                self.left_pad = padding[1]\\r\\n                self.right_pad = padding[1]\\r\\n            elif len(padding) == 4:\\r\\n                self.top_pad = padding[0]\\r\\n                self.bottom_pad = padding[1]\\r\\n                self.left_pad = padding[2]\\r\\n                self.right_pad = padding[3]\\r\\n            else:\\r\\n                raise TypeError(\\'`padding` should be tuple of int \\'\\r\\n                                \\'of length 2 or 4, or dict. \\'\\r\\n                                \\'Found: \\' + str(padding))\\r\\n\\r\\n        # if data_format not in {\\'channels_last\\'}:\\r\\n        #     raise ValueError(\\'data_format must be in {\"channels_last\"}.\\')\\r\\n        self.data_format = data_format\\r\\n        self.input_spec = [InputSpec(ndim=4)]\\r\\n\\r\\n    def call(self, x, mask=None):\\r\\n        \"\"\"Call x to apply padding.\"\"\"\\r\\n        top_pad = self.top_pad\\r\\n        bottom_pad = self.bottom_pad\\r\\n        left_pad = self.left_pad\\r\\n        right_pad = self.right_pad\\r\\n\\r\\n        paddings = [[0, 0], [left_pad, right_pad],\\r\\n                    [top_pad, bottom_pad], [0, 0]]\\r\\n\\r\\n        return tf.pad(x, paddings, mode=\\'REFLECT\\', name=None)\\r\\n\\r\\n    def compute_output_shape(self, input_shape):\\r\\n        \"\"\"\\r\\n        Compute the shape of output.\\r\\n\\r\\n        Parameters:\\r\\n        --------\\r\\n        input_shape: Tuple\\r\\n        shape of input\\r\\n        \"\"\"\\r\\n        if self.data_format == \\'channels_last\\':\\r\\n            rows = input_shape[1] + self.top_pad + self.bottom_pad\\r\\n            cols = input_shape[2] + self.left_pad + self.right_pad\\r\\n\\r\\n            return (input_shape[0],\\r\\n                    rows,\\r\\n                    cols,\\r\\n                    input_shape[3])\\r\\n        else:\\r\\n            raise ValueError(\\'Invalid data_format:\\', self.data_format)\\r\\n\\r\\n    def get_config(self):\\r\\n        \"\"\"Get the Configure.\"\"\"\\r\\n        config = {\\'padding\\': self.padding}\\r\\n        base_config = super(ReflectionPadding2D, self).get_config()\\r\\n        return dict(list(base_config.items()) + list(config.items()))\\r\\n\\r\\n\\r\\nclass UnPooling2D(UpSampling2D):\\r\\n    \"\"\"Unpool 2D from 2D upsampling.\"\"\"\\r\\n\\r\\n    def __init__(self, size=(2, 2)):\\r\\n        \"\"\"Construct size.\"\"\"\\r\\n        super(UnPooling2D, self).__init__(size)\\r\\n\\r\\n    def call(self, x, mask=None):\\r\\n        \"\"\"Call th x data.\"\"\"\\r\\n        shapes = x.get_shape().as_list()\\r\\n        w = self.size[0] * shapes[1]\\r\\n        h = self.size[1] * shapes[2]\\r\\n        return tf.image.resize(x, (w, h))\\r\\n\\r\\n\\r\\nclass InstanceNormalize(Layer):\\r\\n    \"\"\"Normalization Instance of class.\"\"\"\\r\\n\\r\\n    def __init__(self, **kwargs):\\r\\n        \"\"\"Initialize the keyaarguments.\"\"\"\\r\\n        super(InstanceNormalize, self).__init__(**kwargs)\\r\\n        self.epsilon = 1e-3\\r\\n\\r\\n    def call(self, x, mask=None):\\r\\n        \"\"\"Call mean and variance for normalization.\"\"\"\\r\\n        mean, var = tf.nn.moments(x, [1, 2], keep_dims=True)\\r\\n        return tf.div(tf.subtract(x, mean), tf.sqrt(tf.add(var, self.epsilon)))\\r\\n\\r\\n    def compute_output_shape(self, input_shape):\\r\\n        \"\"\"Compute the shape of output.\"\"\"\\r\\n        return input_shape\\r\\n\\r\\n\\r\\nclass RepeatConv(Layer):\\r\\n    \"\"\"\\r\\n    Repeats the input n times.\\r\\n\\r\\n    Example:\\r\\n    -------\\r\\n        model = Sequential()\\r\\n        model.add(Dense(32, input_dim=32))\\r\\n        now: model.output_shape == (None, 32)\\r\\n        note: `None` is the batch dimension\\r\\n        model.add(RepeatVector(3))\\r\\n        now: model.output_shape == (None, 3, 32)\\r\\n\\r\\n    Arguments\\r\\n    ---------\\r\\n        n: integer, repetition factor.\\r\\n    Input shape\\r\\n    ----------\\r\\n        4D tensor of shape `(num_samples, w, h, c)`.\\r\\n    Output shape\\r\\n    -----------\\r\\n        5D tensor of shape `(num_samples, n, w, h, c)`.\\r\\n    \"\"\"\\r\\n\\r\\n    def __init__(self, n, **kwargs):\\r\\n        \"\"\"Initialize the class parameters.\"\"\"\\r\\n        super(RepeatConv, self).__init__(**kwargs)\\r\\n        self.n = n\\r\\n        self.input_spec = InputSpec(ndim=4)\\r\\n\\r\\n    def compute_output_shape(self, input_shape):\\r\\n        \"\"\"Compute output shape.\"\"\"\\r\\n        return (input_shape[0], self.n, input_shape[1],\\r\\n                input_shape[2], input_shape[3])\\r\\n\\r\\n    def call(self, inputs):\\r\\n        \"\"\"Call the inputs.\"\"\"\\r\\n        x = K.expand_dims(inputs, 1)\\r\\n        pattern = tf.stack([1, self.n, 1, 1, 1])\\r\\n        return K.tile(x, pattern)\\r\\n\\r\\n    def get_config(self):\\r\\n        \"\"\"Get configure.\"\"\"\\r\\n        config = {\\'n\\': self.n}\\r\\n        base_config = super(RepeatConv, self).get_config()\\r\\n        return dict(list(base_config.items()) + list(config.items()))\\r\\n',\n",
              " 'unet_uae.py': b'\"\"\"Path hack to make tests work.\"\"\"\\r\\nfrom layers import *\\r\\nfrom keras import backend as K\\r\\nfrom keras.layers import Input, Flatten, Dense, Lambda, Reshape\\r\\nfrom keras.layers import concatenate, TimeDistributed, RepeatVector, ConvLSTM2D\\r\\nfrom keras.models import Model\\r\\nimport numpy as np\\r\\n\\r\\n\\r\\ndef create_vae(input_shape, depth):\\r\\n    \"\"\"\\r\\n    Create VAE to create something new.\\r\\n\\r\\n    Parameters:\\r\\n    -------\\r\\n    input_shape : Tuple\\r\\n    depth : int\\r\\n    Returns:\\r\\n    -------\\r\\n    encoder: encoder\\r\\n    model : recurrnet R-UNET model\\r\\n\\r\\n    \"\"\"\\r\\n    # Encoder\\r\\n    input = Input(shape=input_shape, name=\\'image\\')\\r\\n\\r\\n    enc1 = conv_bn_relu(16, 3, 3, stride=(2, 2))(input)\\r\\n    time_enc1 = RepeatConv(depth)(enc1)\\r\\n    enc2 = conv_bn_relu(32, 3, 3, stride=(1, 1))(enc1)\\r\\n    time_enc2 = RepeatConv(depth)(enc2)\\r\\n    enc3 = conv_bn_relu(64, 3, 3, stride=(2, 2))(enc2)\\r\\n    time_enc3 = RepeatConv(depth)(enc3)\\r\\n    enc4 = conv_bn_relu(128, 3, 3, stride=(1, 1))(enc3)\\r\\n    time_enc4 = RepeatConv(depth)(enc4)\\r\\n\\r\\n    x = res_conv(128, 3, 3)(enc4)\\r\\n    x = res_conv(128, 3, 3)(x)\\r\\n    x = res_conv(128, 3, 3)(x)\\r\\n\\r\\n    encoder = Model(input, x, name=\\'encoder\\')\\r\\n\\r\\n    x = RepeatConv(depth)(enc4)\\r\\n    x = ConvLSTM2D(128, (3, 3), strides=(1, 1),\\r\\n                   padding=\\'same\\', activation=\\'relu\\',\\r\\n                   return_sequences=True)(x)\\r\\n    # x = ConvLSTM2D(64, (3, 3), strides=(1, 1), padding = \\'same\\',\\r\\n    # activation=\\'relu\\', return_sequences = True)(x)\\r\\n    # x = ConvLSTM2D(128, (3, 3), strides=(1, 1), padding = \\'same\\',\\r\\n    # activation=\\'relu\\', return_sequences = True)(x)\\r\\n    x = time_res_conv(128, 3, 3)(x)\\r\\n    x = time_res_conv(128, 3, 3)(x)\\r\\n    dec4 = time_res_conv(128, 3, 3)(x)\\r\\n\\r\\n    merge4 = concatenate([time_enc4, dec4], axis=4)\\r\\n    dec3 = time_dconv_bn_nolinear(128, 3, 3, stride=(1, 1))(merge4)\\r\\n    merge3 = concatenate([time_enc3, dec3], axis=4)\\r\\n    dec2 = time_dconv_bn_nolinear(64, 3, 3, stride=(2, 2))(merge3)\\r\\n    merge2 = concatenate([time_enc2, dec2], axis=4)\\r\\n    dec1 = time_dconv_bn_nolinear(32, 3, 3, stride=(1, 1))(merge2)\\r\\n    merge1 = concatenate([time_enc1, dec1], axis=4)\\r\\n    dec0 = time_dconv_bn_nolinear(16, 3, 3, stride=(2, 2))(merge1)\\r\\n\\r\\n    output = TimeDistributed(Conv2D(1, (3, 3), padding=\\'same\\',\\r\\n                                    activation=None))(dec0)\\r\\n    print(\\'output shape is \\', K.int_shape(output))\\r\\n    # Full net\\r\\n    full_model = Model(input, output)\\r\\n\\r\\n    return full_model, encoder\\r\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCrWDL1qVfMw"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import unet_uae as vae_util\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.python.keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf \n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "K.set_session(sess)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zr0u9vQzf5R",
        "outputId": "b8b8bd4e-b109-4033-f767-719718daceff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlbNGMtBA_Fs"
      },
      "source": [
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    Function to load datasets in format .NPY\n",
        "    \n",
        "    Parameter:\n",
        "    ----------\n",
        "    path : string\n",
        "        The absolute path of where data saved in local system\n",
        "        \n",
        "    Return:\n",
        "    ----------\n",
        "    loaded_data : ndarray\n",
        "        The data which was loaded\n",
        "    \"\"\"\n",
        "    loaded_data = np.load(path)\n",
        "    return loaded_data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cErfklo76F21"
      },
      "source": [
        "# Two common methods for feature scaling is : 1-Normalization & 2-Standardaisation\n",
        "\n",
        "def normalize(data):\n",
        "    \"\"\"\n",
        "    this function used for Max-Min Normalization (Min-Max scaling) by re-scaling\n",
        "    features with a distribution value between 0 and 1. For every feature,the minimum\n",
        "    value of that feature gets transformed into 0, and the maximum value \n",
        "    gets transformed into 1\n",
        "    \n",
        "    Parameter:\n",
        "    ----------\n",
        "    data : ndarray\n",
        "        The numpy array which we want to normalize\n",
        "        \n",
        "    Return:\n",
        "    ----------\n",
        "    norm_data : ndarray\n",
        "        The normalized data which transformed into 0 and 1\n",
        "    \"\"\"\n",
        "    max_p = np.max(data[:, :, :, :])\n",
        "    min_p = np.min(data[:, :, :, :])\n",
        "    norm_data = (data - min_p)/(max_p - min_p)\n",
        "    return norm_data\n",
        "\n",
        "def standardize(data):\n",
        "    \"\"\"\n",
        "    this function used for rescaling faetures to ensure the mean\n",
        "    and the standard deviation to be 0 and 1, respectively.\n",
        "    \n",
        "    Parameter:\n",
        "    ----------\n",
        "    data : ndarray\n",
        "        The numpy array which we want to normalize\n",
        "        \n",
        "    Return:\n",
        "    ----------\n",
        "    data : ndarray\n",
        "        The standardized data which the mean\n",
        "    and the standard deviation to be 0 and 1\n",
        "    \"\"\"\n",
        "    data_mean = np.mean(data[:, :, :, :], axis = 0, keepdims = True)\n",
        "    data_std = np.std(data[:, :, :, :], axis = 0, keepdims = True)\n",
        "    std_data = (data - data_mean)/(data_std)\n",
        "    return std_data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uviUO--fC_pp"
      },
      "source": [
        "# define the absolute path of training datatsat\n",
        "path_perm = '/content/gdrive/MyDrive/perm.npy'\n",
        "path_press = '/content/gdrive/MyDrive/pressure.npy'\n",
        "# use load_data function nd above path to loading data\n",
        "X_data= load_data(path_perm)\n",
        "target_data = load_data(path_press)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5s3_Zex6sQs"
      },
      "source": [
        "# Normalize data using abov normalize function\n",
        "train_nr = 2250\n",
        "test_nr = 750"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yq6Ouns_EIN",
        "outputId": "7c60dad9-303d-4f30-b265-ced689c8e5da"
      },
      "source": [
        "p_t_mean = np.mean(target_data[:train_nr, ...], axis = 0, keepdims = True)\n",
        "target_data = target_data - p_t_mean\n",
        "print('max p is ', np.max(target_data[:train_nr, ...]), ', min p is ', np.min(target_data[:train_nr, ...]))\n",
        "max_p = np.max(target_data[:train_nr, ...])\n",
        "min_p = np.min(target_data[:train_nr, ...])\n",
        "target_data = (target_data - min_p)/(max_p -min_p) - 0.5\n",
        "print('max p is ', np.max(target_data), ', min p is ', np.min(target_data))\n",
        "print('max p train is ', np.max(target_data[:train_nr, ...]), ', min p train is ', np.min(target_data[:train_nr, ...]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max p is  516.6753418240017 , min p is  -135.6267126736111\n",
            "max p is  0.5039995270719013 , min p is  -0.500166926837037\n",
            "max p train is  0.5 , min p train is  -0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q5C0284nFxJ",
        "outputId": "539208d5-a86d-419c-dce5-7a6af9294c94"
      },
      "source": [
        "input_shape=(100, 100, 2)\n",
        "depth = 10\n",
        "vae_model,_ = vae_util.create_vae(input_shape, depth)\n",
        "vae_model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output shape is  (None, 10, 100, 100, 1)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "image (InputLayer)              [(None, 100, 100, 2) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 50, 50, 16)   304         image[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 50, 50, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 50, 50, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 50, 50, 32)   4640        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 50, 50, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 50, 50, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 25, 25, 64)   18496       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 25, 25, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 25, 25, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 25, 25, 128)  73856       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 25, 25, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 25, 25, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "repeat_conv_4 (RepeatConv)      (None, 10, 25, 25, 1 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)       (None, 10, 25, 25, 1 1180160     repeat_conv_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 10, 25, 25, 1 147584      conv_lst_m2d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 10, 25, 25, 1 512         time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 10, 25, 25, 1 0           conv_lst_m2d[0][0]               \n",
            "                                                                 time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistrib (None, 10, 25, 25, 1 147584      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_9 (TimeDistrib (None, 10, 25, 25, 1 512         time_distributed_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 10, 25, 25, 1 0           add_3[0][0]                      \n",
            "                                                                 time_distributed_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_13 (TimeDistri (None, 10, 25, 25, 1 147584      add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_14 (TimeDistri (None, 10, 25, 25, 1 512         time_distributed_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "repeat_conv_3 (RepeatConv)      (None, 10, 25, 25, 1 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 10, 25, 25, 1 0           add_4[0][0]                      \n",
            "                                                                 time_distributed_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 10, 25, 25, 2 0           repeat_conv_3[0][0]              \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_15 (TimeDistri (None, 10, 25, 25, 2 0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_16 (TimeDistri (None, 10, 27, 27, 2 0           time_distributed_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_17 (TimeDistri (None, 10, 25, 25, 1 295040      time_distributed_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_18 (TimeDistri (None, 10, 25, 25, 1 512         time_distributed_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "repeat_conv_2 (RepeatConv)      (None, 10, 25, 25, 6 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_19 (TimeDistri (None, 10, 25, 25, 1 0           time_distributed_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 10, 25, 25, 1 0           repeat_conv_2[0][0]              \n",
            "                                                                 time_distributed_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_20 (TimeDistri (None, 10, 50, 50, 1 0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_21 (TimeDistri (None, 10, 52, 52, 1 0           time_distributed_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_22 (TimeDistri (None, 10, 50, 50, 6 110656      time_distributed_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_23 (TimeDistri (None, 10, 50, 50, 6 256         time_distributed_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "repeat_conv_1 (RepeatConv)      (None, 10, 50, 50, 3 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_24 (TimeDistri (None, 10, 50, 50, 6 0           time_distributed_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 10, 50, 50, 9 0           repeat_conv_1[0][0]              \n",
            "                                                                 time_distributed_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_25 (TimeDistri (None, 10, 50, 50, 9 0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_26 (TimeDistri (None, 10, 52, 52, 9 0           time_distributed_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_27 (TimeDistri (None, 10, 50, 50, 3 27680       time_distributed_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_28 (TimeDistri (None, 10, 50, 50, 3 128         time_distributed_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "repeat_conv (RepeatConv)        (None, 10, 50, 50, 1 0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_29 (TimeDistri (None, 10, 50, 50, 3 0           time_distributed_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 10, 50, 50, 4 0           repeat_conv[0][0]                \n",
            "                                                                 time_distributed_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_30 (TimeDistri (None, 10, 100, 100, 0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_31 (TimeDistri (None, 10, 102, 102, 0           time_distributed_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_32 (TimeDistri (None, 10, 100, 100, 6928        time_distributed_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_33 (TimeDistri (None, 10, 100, 100, 64          time_distributed_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_34 (TimeDistri (None, 10, 100, 100, 0           time_distributed_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_35 (TimeDistri (None, 10, 100, 100, 145         time_distributed_34[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 2,164,113\n",
            "Trainable params: 2,162,385\n",
            "Non-trainable params: 1,728\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4PDSq-qnONZ",
        "outputId": "25d4a605-f2c6-4fd4-81f5-f4d6e0dc69d8"
      },
      "source": [
        "depth = 10\n",
        "nr = X_data.shape[0]\n",
        "train_nr = 2250\n",
        "test_nr = 750\n",
        "train_x = np.concatenate([X_data[:train_nr,[0], ...],target_data[:train_nr,[0], ...]], axis = 1)\n",
        "train_y = target_data[:train_nr, ...]\n",
        "\n",
        "test_x = np.concatenate([X_data[nr-test_nr:,[0], ...], target_data[nr-test_nr:, [0], ...]], axis = 1)\n",
        "test_y = target_data[nr-test_nr:,...]\n",
        "\n",
        "\n",
        "train_x = train_x.transpose(0,2,3,1)\n",
        "train_y = train_y[:,:,:,:,None]\n",
        "test_x = test_x.transpose(0,2,3,1)\n",
        "test_y = test_y[:,:,:,:,None]\n",
        "#test_y = test_y.transpose(0,2,3,1)\n",
        "print('train_x shape is ', train_x.shape)\n",
        "print('train_y shape is ', train_y.shape)\n",
        "print('test_x shape is ', test_x.shape)\n",
        "print('test_y shape is ', test_y.shape)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x shape is  (2250, 100, 100, 2)\n",
            "train_y shape is  (2250, 10, 100, 100, 1)\n",
            "test_x shape is  (750, 100, 100, 2)\n",
            "test_y shape is  (750, 10, 100, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxsuLGQpniCs"
      },
      "source": [
        "output_dir = '/content/gdrive/MyDrive/Colab Notebooks/saved_models/'\n",
        "epochs = 300\n",
        "batch_size = 32\n",
        "num_batch = int(train_nr/batch_size) "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EqIECRbnoTX"
      },
      "source": [
        "def vae_loss(x, t_decoded):\n",
        "    '''Total loss for the plain UAE'''\n",
        "    return K.mean(reconstruction_loss(x, t_decoded))\n",
        "\n",
        "\n",
        "def reconstruction_loss(x, t_decoded):\n",
        "    '''Reconstruction loss for the plain UAE'''\n",
        "\n",
        "    return K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2, axis=-1)\n",
        "\n",
        "def relative_error(x, t_decoded):\n",
        "    return K.mean(K.abs(x - t_decoded) / x)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m46Y8eknsmA"
      },
      "source": [
        "opt = Adam(learning_rate=1e-4)\n",
        "vae_model.compile(loss = vae_loss, optimizer = opt, metrics = [relative_error])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lttghynSnzzT"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "lrScheduler = ReduceLROnPlateau(monitor = 'loss', factor = 0.5, patience = 15, cooldown = 1, verbose = 1, min_lr = 1e-6)\n",
        "filePath = 'saved-model-{epoch:03d}-{val_loss:.2f}.h5'\n",
        "checkPoint = ModelCheckpoint(filePath, monitor = 'val_loss', verbose = 1, save_best_only = False, \\\n",
        "                             save_weights_only = True, mode = 'auto', save_freq = 20)\n",
        "\n",
        "callbacks_list = [lrScheduler, checkPoint]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "ClmgwTn9n7Dv",
        "outputId": "5146d001-344e-494d-8d4f-2df526269619"
      },
      "source": [
        "history = vae_model.fit(train_x, train_y, batch_size = batch_size, epochs = epochs, \\\n",
        "                        verbose = 1, validation_data = (test_x, test_y))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-687f6487cbfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[320,52,52,192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/time_distributed_21/reflection_padding2d_1/MirrorPad (defined at /content/layers.py:283) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_8023]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/time_distributed_21/reflection_padding2d_1/MirrorPad:\n model/time_distributed_21/Reshape (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py:262)\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5j_VWLCPY0H"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(np.abs(history.history['relative_error']))\n",
        "plt.plot(np.abs(history.history['val_relative_error']))\n",
        "plt.title('model relative error')\n",
        "plt.ylabel('relative error')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.savefig('/content/gdrive/MyDrive/Gridsearch_images/pressure_lr1-4_300epochs_adam_batch32.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWPXacBAry0S",
        "outputId": "3bb6186a-7ab0-4916-f6d0-709db325de5d"
      },
      "source": [
        "#vae_model.save(\"/content/gdrive/MyDrive/saved_models/pressure_le1-2.h5\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}