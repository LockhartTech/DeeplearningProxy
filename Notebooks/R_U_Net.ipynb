{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R-U-Net.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqYFt2kx55dqoHUdX6xiMx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acse-srm3018/DeeplearningProxy/blob/main/R_U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myMbDzciXJdr"
      },
      "source": [
        "A few imports before we get started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QJWxL-WXMJb"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from core.modules import ResidualConv, Upsample\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfyoYdYbfZjC"
      },
      "source": [
        "## Create a Residual U-Net as a nn.Module\n",
        "## Create a feed-forward neural network with the following architecture:\n",
        "\n",
        "### Encoder\n",
        "Input layer : Nx;Ny;2\n",
        "- Convolutional layer:  16 \flters of size 3 \u0002 3 \u0002 2, stride 2 (Nx=2;Ny=2; 16)\n",
        "- Convolutional layer: 32 \flters of size 3 \u0002 3 \u0002 16, stride 1 (Nx=2;Ny=2; 32)\n",
        "- Convolutional layer: 64 \flters of size 3 \u0002 3 \u0002 32, stride 2 (Nx=4;Ny=4; 64)\n",
        "- Convolutional layer: 128 \flters of size 3 \u0002 3 \u0002 64, stride 1 (Nx=4;Ny=4; 128)\n",
        "- Residual layer: 128 \flters (Nx=4;Ny=4; 128)\n",
        "- Residual layer: 128 \flters (Nx=4;Ny=4; 128)\n",
        "- Residual layer: 128 \flters (Nx=4;Ny=4; 128)\n",
        "\n",
        "### Decoder\n",
        "- Residual layer: 128 \flters (Nx=4;Ny=4; 128;Nt)\n",
        "- Residual layer: 128 \flters (Nx=4;Ny=4; 128;Nt)\n",
        "- Residual layer: 128 \flters (Nx=4;Ny=4; 128;Nt)\n",
        "- Transposed convolutional: 128 \flters of size 3 \u0002 3 \u0002 128, stride 1 (Nx=4;Ny=4; 128;Nt)\n",
        "- Transposed convolutional: 64 \flters of size 3 \u0002 3 \u0002 128, stride 2 (Nx=2;Ny=2; 64;Nt)\n",
        "- Transposed convolutional: 32 \flters of size 3 \u0002 3 \u0002 64, stride 1 (Nx=2;Ny=2; 32;Nt)\n",
        "- Tranposed convolutional: 16 \flters of size 3 \u0002 3 \u0002 32, stride 2 (Nx;Ny; 16;Nt)\n",
        "- Convolutional layer: 1 \flter of size 3 \u0002 3 \u0002 16, stride 1 (Nx;Ny; 1;Nt)\n",
        "\n",
        "- Output Layer Activation: None"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8d45JMzGsL7"
      },
      "source": [
        "class ResUnet(nn.Module):\n",
        "    def __init__(self, channel, filters=[64, 128, 256, 512]):\n",
        "        super(ResUnet, self).__init__()\n",
        "\n",
        "        self.input_layer = nn.Sequential(\n",
        "            nn.Conv2d(channel, filters[0], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(filters[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(filters[0], filters[0], kernel_size=3, padding=1),\n",
        "        )\n",
        "        self.input_skip = nn.Sequential(\n",
        "            nn.Conv2d(channel, filters[0], kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.residual_conv_1 = ResidualConv(filters[0], filters[1], 2, 1)\n",
        "        self.residual_conv_2 = ResidualConv(filters[1], filters[2], 2, 1)\n",
        "\n",
        "        self.bridge = ResidualConv(filters[2], filters[3], 2, 1)\n",
        "\n",
        "        self.upsample_1 = Upsample(filters[3], filters[3], 2, 2)\n",
        "        self.up_residual_conv1 = ResidualConv(filters[3] + filters[2], filters[2], 1, 1)\n",
        "\n",
        "        self.upsample_2 = Upsample(filters[2], filters[2], 2, 2)\n",
        "        self.up_residual_conv2 = ResidualConv(filters[2] + filters[1], filters[1], 1, 1)\n",
        "\n",
        "        self.upsample_3 = Upsample(filters[ 1], filters[1], 2, 2)\n",
        "        self.up_residual_conv3 = ResidualConv(filters[1] + filters[0], filters[0], 1, 1)\n",
        "\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Conv2d(filters[0], 1, 1, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode\n",
        "        x1 = self.input_layer(x) + self.input_skip(x)\n",
        "        x2 = self.residual_conv_1(x1)\n",
        "        x3 = self.residual_conv_2(x2)\n",
        "        # Bridge\n",
        "        x4 = self.bridge(x3)\n",
        "        # Decode\n",
        "        x4 = self.upsample_1(x4)\n",
        "        x5 = torch.cat([x4, x3], dim=1)\n",
        "\n",
        "        x6 = self.up_residual_conv1(x5)\n",
        "\n",
        "        x6 = self.upsample_2(x6)\n",
        "        x7 = torch.cat([x6, x2], dim=1)\n",
        "\n",
        "        x8 = self.up_residual_conv2(x7)\n",
        "\n",
        "        x8 = self.upsample_3(x8)\n",
        "        x9 = torch.cat([x8, x1], dim=1)\n",
        "\n",
        "        x10 = self.up_residual_conv3(x9)\n",
        "\n",
        "        output = self.output_layer(x10)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
